{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LR_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrRBkfXLP9C"
      },
      "source": [
        "# Before you start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMDl8eAR2LjT"
      },
      "source": [
        "**First downloaded the USA_Housing.csv and checker.py from github, link is:** https://github.com/UCLA-LACC-21/M4-ML-AI\n",
        "**Then you need to drag/upload the two files into this colab session (click the files button on the left of this notebook and drag the files to it).**\n",
        "\n",
        "There are three examples in this lab, which is designed to let you familiar with basic ML algorithm implementation in python and how to implement them, along with different kinds of useful libraries. For two fo the examples, you need to write one or two lines of code yourself, and the checker function will let you know whether it is correctly implemented or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBysbL1InfNc"
      },
      "source": [
        "# Linear regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCa9LVusVGd9"
      },
      "source": [
        "First, let's start with a very basic example and implement linear regression from scratch using the formula. Let X be some random numbers that follows normal distribution with mean = 1.5 and stddev = 2.5, and target y is computed using the equaltion y = 2 + 0.3 * X + res, where res is the residual term which also follows normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o4pKG0LZmMF"
      },
      "source": [
        "import checker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Generate 'random' data\n",
        "np.random.seed(0)\n",
        "X = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5\n",
        "res = 0.5 * np.random.randn(100)       # Generate 100 residual terms\n",
        "y = 2 + 0.3 * X + res                  # Actual values of Y\n",
        "\n",
        "# Create pandas dataframe to store our X and y values\n",
        "df = pd.DataFrame(\n",
        "    {'X': X,\n",
        "     'y': y}\n",
        ")\n",
        "\n",
        "# Show the first five rows of our dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CFWEIwiI0I5"
      },
      "source": [
        "Now we have generated our own data for linear regression. Let's calculate the alpha and beta terms using the equations. Here alpha is the beta0 term in lecture slides, which is the intercept of the line. \n",
        "\n",
        "**In this block there is one line of code that you need to implement yourself**, which is to calculate the alpha value based on the formula. Once you finish the implementation, run this block and the checker function will let you know whether you implement it correctly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBi-hVXzxReL"
      },
      "source": [
        "# Calculate the mean of X and y\n",
        "xmean = np.mean(X)\n",
        "ymean = np.mean(y)\n",
        "\n",
        "# Calculate the terms needed for the numator and denominator of beta\n",
        "df['xycov'] = (df['X'] - xmean) * (df['y'] - ymean)\n",
        "df['xvar'] = (df['X'] - xmean)**2\n",
        "\n",
        "# Calculate beta and alpha, no multi-dimentional matrix operations here since we are processing with 1d data.\n",
        "beta = df['xycov'].sum() / df['xvar'].sum()\n",
        "#######################################\n",
        "#your code here to calculate alpha, remember alpha is the intercept of the line\n",
        "alpha = \n",
        "########################################\n",
        "print(f'alpha = {alpha}')\n",
        "print(f'beta = {beta}')\n",
        "checker.check_alpha(alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocO7-nwVJtqq"
      },
      "source": [
        "Generate the predicted y values based on our alpha and beta values, and the input X.\n",
        "\n",
        "**This is one line of code essentially implement the function of a straight line, you should try to implement it yourself.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7fzzorqyTqn"
      },
      "source": [
        "###############################\n",
        "#implement the one line code to generate y (prediction) according to calculated alpha and beta value and input X\n",
        "ypred = \n",
        "###############################\n",
        "checker.check_ypred(ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WE_CIIAJ5yf"
      },
      "source": [
        "To visualize how our regressor performs, plot the regression results against the actual y we generated. The blue line is our line of best fit, Yâ‚‘ = 2.003 + 0.323 X. We can see from this graph that there is a positive linear relationship between X and y. Using our model, we can predict y from any values of X!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImkHL3UUyXkQ"
      },
      "source": [
        "# Plot regression against actual data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(X, ypred)     # regression line\n",
        "plt.plot(X, y, 'ro')   # scatter plot showing actual data\n",
        "plt.title('Actual vs Predicted')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDscPLJWKZBu"
      },
      "source": [
        "Now we have finished the first example! It's a toy example that makes you understand better what's happening. \n",
        "\n",
        "Now let's try another exmaple, unlike the first example, this time we use a real-world dataset: USA Housing. The dataset involves many information of housing including area income, house age, number of rooms, etc., and the goal is to use these information to predict the price of the house. \n",
        "In real world, data usually are not 1d like the one we generated our seleves, but involves many dimensions, this USA housing dataset has 6 dimensions for example. In such cases, computing beta values from scratch will be complex. \n",
        "\n",
        "Luckily, in real world we usually don't implement from scratch, but use libraries (where others implement the function and all you need to do is import and call it). In this example we will use sklearn library which contains lots of Machine learning models and algorithms (If you want to do data science related work in future, you will be using this library a lot!). Besides sklearn, there are also many useful libraries (e.g., seborn) that can help you to visualize and understand the data better, so that you know what kind of algorithms may work better. In this example we will work you through all these libraries and let you familiar with it. **You don't need to implement anything in this example.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b82gCibVNdjc"
      },
      "source": [
        "Fisrt, let's import these libraries and load the dataset from the csv file you uploaded to colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPv72xrEzE_p"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "df = pd.read_csv('./USA_Housing.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLNRiq7yNsWR"
      },
      "source": [
        "Use df.info() to print out the summary of all data colomns (each colomn is one dimension).\n",
        "Why there is 7 colomns here but I said this dataset contains 6 dimensions?\n",
        "A: The price column is Y, which is the output of our prediction and should not be a dimension of input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5oaKNTKz2cm"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQUJe1_GOO1V"
      },
      "source": [
        "df.describe() gives the stats summary of all the columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9hXZtqqz4l1"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KETxUU8xOXh7"
      },
      "source": [
        "Print out all the column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hxqeL_qz8wi"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mUEx2zeObyo"
      },
      "source": [
        "seborn (sns) is a very powerful library for visualizing data, it can make you understand the data a lot better if used correctly.\n",
        "Here we call pairplot to plot the pair-wise relationship between each data columns. As you can see from the plot, some columns has a strong correlation while some seems uncorrelated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO2OjJd0DVq"
      },
      "source": [
        "sns.pairplot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMks-njaPNrz"
      },
      "source": [
        "Now we compute the correlation between columns using df.corr(), and then plot the results as a heat map using sns.heatmap for better visualization. Compare this plot to the previous plot, you can see the correlation numbers verify the pair-wise relationship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhEUHB7r0UfH"
      },
      "source": [
        "sns.heatmap(df.corr(),annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoTfIM9uS_5u"
      },
      "source": [
        "Now let's start the actual regression implementation. First need to define the input data and target. Here the target y is the price column. Only 5 out of the 6 columns are slected here as input data, the address column is excluded, because it contains no useful information about housing price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6U8Euvy1Lsb"
      },
      "source": [
        "X = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
        "       'Avg. Area Number of Bedrooms', 'Area Population']]\n",
        "y= df['Price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67OlCx_iTosQ"
      },
      "source": [
        "Now let's import the sklearn library. Then we use train_test_split to split our data read from csv into training set and test set automatically (test set is used to verify our prediction results and shouldn't be seen during training).\n",
        "\n",
        "Then we implement the linear regression by calling the library. We define the regressor using `regressor = LinearRegression()` and use `regressor.fit(X_train,  y_train)` to compute the alpha and beta values based on the input data.\n",
        "\n",
        "Yes, it is that simple, with two lines of code the regressor model is already trained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33dw0pUj0g3P"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=101)\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train,  y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trlImNWJUxWk"
      },
      "source": [
        "To predict, call `predictions = regressor.predict(X_test)` to get the predicted housing price (ypred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSalw6bc1QIN"
      },
      "source": [
        "predictions = regressor.predict(X_test)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N032wOlX1eBK"
      },
      "source": [
        "Now let's compare the predicted results with the actual price by scatter plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrBQAVI1TP1"
      },
      "source": [
        "plt.scatter(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRBKIbw11s34"
      },
      "source": [
        "Seems pretty good! This example shows that linear regression works well on multi-dimension data as well, and more importantly, it shows linear regression is good enough for some real word dataset like this one.\n",
        "\n",
        "Also, we can see that libraries make our life a lot easier, we can implemnt a linear regression (or a lot other algos) and get the prediction using sklearn with 3 lines of code. Libraries are great, but you should use it with caution as it can hurt you as well. Many people only knows how to call libraries, but don't know what's happening inside at all, and that's what we should avoid.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPIpoalcnYjD"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAL54ggnnlam"
      },
      "source": [
        "Now let try an example with Perceptron, which will be a classification task. In this example I will show you how to implement a perceptron from scratch, whcih is more complex than linear regression. It is designed to help you understand how perceptron works better, you don't have to know how implement from scratch yourself. Just try to understand the code will already be useful.\n",
        "reference: https://pythonmachinelearning.pro/perceptrons-the-first-neural-networks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKkBKQoZnkmX"
      },
      "source": [
        "class Perceptron(object):\n",
        "    \"\"\"Implements a perceptron network\"\"\"\n",
        "    '''\n",
        "    Weâ€™ll use object-oriented principles and create a class. In order to construct our perceptron,\n",
        "    we need to know how many inputs there are to create our weight vector.\n",
        "    The reason we add one to the input size is to include the bias in the weight vector.\n",
        "    '''\n",
        "    def __init__(self, input_size, lr=1, epochs=100):\n",
        "        self.W = np.zeros(input_size+1) # the weight of the perceptron\n",
        "        # add one for bias\n",
        "        self.epochs = epochs #number of epochs for training\n",
        "        self.lr = lr # this is the learning rate for training\n",
        "\n",
        "    '''\n",
        "    Weâ€™ll also need to implement our activation function. We can simply return 1 if the input is greater than or equal to 0 and 0 otherwise.\n",
        "    '''\n",
        "    def activation_fn(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "    '''\n",
        "    Besides, we need a function to run an input through the perceptron and return an output.\n",
        "    Conventionally, this is called the prediction. We add the bias into the input vector. \n",
        "    Then we can simply compute the inner product and apply the activation function.\n",
        "    '''\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a\n",
        "\n",
        "    '''\n",
        "    The previous functions are enough for a forward pass to a perceptron model (given input and weights, the model will generate correct output).\n",
        "    However, we still nees a function to update the weights, i.e., train the network.\n",
        "    With the update rule from lecture in mind, we can create a function to keep applying this update rule until our perceptron can correctly classify all of our inputs.\n",
        "    We need to keep iterating through our training data until this happens; one epoch is when our perceptron has seen all of the training data once.\n",
        "    Usually, we run our learning algorithm for multiple epochs.\n",
        "    '''\n",
        "    def fit(self, X, d):\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(d.shape[0]):\n",
        "                x = np.insert(X[i], 0, 1)\n",
        "                y = self.predict(x)\n",
        "                ########################\n",
        "                #your code here (should be just one line)\n",
        "                #how to compute weight? remember here d is the target data for training (fitting)\n",
        "                #you will know whether the implementation is correct or not after running the next block\n",
        "                e = \n",
        "                ###########################\n",
        "                #Then update the weights according to the error, note how learning rate is integrated into it\n",
        "                self.W = self.W + self.lr * e * x \n",
        "    '''\n",
        "    We also want a function to do the actual prediction (inference) which takes an input array.\n",
        "    We can adapted the code from self.predict\n",
        "    '''\n",
        "    def inference(self, X):\n",
        "        ypred = np.zeros(X.shape[0])\n",
        "        for i in range(X.shape[0]):\n",
        "            x = np.insert(X[i], 0, 1)\n",
        "            ypred[i] = self.predict(x)\n",
        "        return ypred\n",
        "    '''\n",
        "    Now we have finished our own perceptron implementation, we now perform a simple test to verify it.\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDAUJmzDtBLs"
      },
      "source": [
        "#Let's generate some random input and target data\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "#y = np.array([0, 0, 0, 0, 1])\n",
        "y = np.array([0, 1, 1, 1, 1])\n",
        "#Then call our implemented perceptron class\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "checker.check_perceptron(perceptron.W)\n",
        "\n",
        "#print the weight of trained perceptron\n",
        "print(perceptron.W)\n",
        "\n",
        "#print the predicted y\n",
        "ypred = perceptron.inference(X)\n",
        "print(ypred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}